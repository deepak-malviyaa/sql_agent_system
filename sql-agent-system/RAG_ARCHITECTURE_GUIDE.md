# RAG (Retrieval-Augmented Generation) in SQL Agent System

## ğŸ“š What is RAG?

**RAG** combines **retrieval** (finding relevant information) with **generation** (creating responses using LLMs) to produce more accurate, context-aware answers.

### Traditional LLM Problem:
```
User: "Show me revenue from Germany"
LLM: SELECT SUM(amount) FROM sales WHERE location = 'DE'  âŒ
      â””â”€ Hallucinates table name, column names, country code
```

### RAG Solution:
```
User: "Show me revenue from Germany"
  â†“
[1. RETRIEVAL] Search schema docs for "revenue" and "Germany"
  â†“
Retrieved Context:
  - Table: sales_data
  - Column: total_revenue (for revenue)
  - Column: country (values: 'USA', 'Germany', 'France', ...)
  â†“
[2. AUGMENTED GENERATION] LLM receives query + schema context
  â†“
LLM: SELECT SUM(total_revenue) FROM sales_data WHERE country = 'Germany' âœ…
      â””â”€ Accurate table/column names from retrieved context
```

---

## ğŸ—ï¸ How RAG Works in This System

### Architecture Flow:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. EMBEDDING PHASE (One-time setup)                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Schema Documentation (Text)                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚ "Table: sales_data                        â”‚                  â”‚
â”‚  â”‚  Columns: id, transaction_date,           â”‚                  â”‚
â”‚  â”‚  total_revenue, country...                â”‚                  â”‚
â”‚  â”‚  Valid countries: USA, Germany, France"   â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                    â†“                                             â”‚
â”‚         [HuggingFace Embeddings Model]                          â”‚
â”‚         sentence-transformers/all-MiniLM-L6-v2                  â”‚
â”‚                    â†“                                             â”‚
â”‚  Vector Representation (384 dimensions)                          â”‚
â”‚  [0.23, -0.45, 0.67, 0.12, ..., -0.89]                         â”‚
â”‚                    â†“                                             â”‚
â”‚  Store in PostgreSQL with pgvector                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚ schema_embeddings table:                  â”‚                  â”‚
â”‚  â”‚ - content: "Table: sales_data..."         â”‚                  â”‚
â”‚  â”‚ - embedding: vector(384)                  â”‚                  â”‚
â”‚  â”‚ - table_name: sales_data                  â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. QUERY PHASE (Every user request)                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  User Query: "Show me revenue from Germany"                     â”‚
â”‚                    â†“                                             â”‚
â”‚         [Convert to Vector]                                      â”‚
â”‚         Using same embeddings model                             â”‚
â”‚                    â†“                                             â”‚
â”‚  Query Vector: [0.21, -0.43, 0.69, ...]                        â”‚
â”‚                    â†“                                             â”‚
â”‚  [Similarity Search in PostgreSQL]                              â”‚
â”‚  SELECT * FROM schema_embeddings                                â”‚
â”‚  ORDER BY embedding <=> query_vector  -- cosine distance        â”‚
â”‚  LIMIT 3;                                                        â”‚
â”‚                    â†“                                             â”‚
â”‚  Top 3 Most Similar Docs:                                       â”‚
â”‚  1. "Table: sales_data, Column: total_revenue..." (dist: 0.15)  â”‚
â”‚  2. "Country values: USA, Germany, France..." (dist: 0.18)      â”‚
â”‚  3. "Revenue calculations: SUM(total_revenue)" (dist: 0.22)     â”‚
â”‚                    â†“                                             â”‚
â”‚  [Augmented Prompt to LLM]                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚ Context:                                  â”‚                  â”‚
â”‚  â”‚ <retrieved schema docs>                   â”‚                  â”‚
â”‚  â”‚                                            â”‚                  â”‚
â”‚  â”‚ User Question:                             â”‚                  â”‚
â”‚  â”‚ Show me revenue from Germany              â”‚                  â”‚
â”‚  â”‚                                            â”‚                  â”‚
â”‚  â”‚ Generate SQL query using provided schema. â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                    â†“                                             â”‚
â”‚  [LLM Generates Accurate SQL]                                   â”‚
â”‚  SELECT SUM(total_revenue) FROM sales_data                      â”‚
â”‚  WHERE country = 'Germany';                                     â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”¢ Vector Similarity Math

### Cosine Distance Formula:
```
distance = 1 - (A Â· B) / (||A|| Ã— ||B||)

Where:
- A Â· B = dot product (sum of element-wise multiplication)
- ||A|| = vector magnitude (sqrt of sum of squares)
- Range: 0 (identical) to 2 (opposite directions)
```

### Example:
```python
# Query: "revenue from Germany"
query_vector = [0.5, 0.8, -0.3]

# Schema Doc 1: "total_revenue column"
doc1_vector = [0.6, 0.7, -0.2]
cosine_distance = 0.12  # Very similar! âœ…

# Schema Doc 2: "employee salary"
doc2_vector = [-0.4, 0.2, 0.9]
cosine_distance = 1.85  # Not relevant âŒ
```

---

## ğŸ—„ï¸ External Database Options for RAG

### Option 1: PostgreSQL + pgvector â­ (RECOMMENDED)
**What we're implementing**

#### Pros:
- âœ… Same database as your data (no separate infrastructure)
- âœ… Persistent storage (survives restarts)
- âœ… ACID transactions (data integrity)
- âœ… SQL interface (familiar queries)
- âœ… Incremental updates (add schemas without full rebuild)
- âœ… Scales to millions of vectors
- âœ… Open source and free

#### Cons:
- âŒ Requires PostgreSQL extension installation
- âŒ Slightly slower than specialized vector DBs for huge datasets

#### Setup:
```bash
# 1. Install pgvector extension
sudo apt-get install postgresql-15-pgvector

# 2. Enable in database
psql -d your_database -c "CREATE EXTENSION vector;"

# 3. System auto-creates schema_embeddings table
python main.py  # Automatically initializes on first run
```

---

### Option 2: Pinecone (Managed Cloud)

#### Pros:
- âœ… Fully managed (no infrastructure)
- âœ… Fastest similarity search (<10ms)
- âœ… Built-in metadata filtering
- âœ… Auto-scaling

#### Cons:
- âŒ Costs $70+/month for production
- âŒ External dependency (network latency)
- âŒ Vendor lock-in

#### Setup:
```python
from langchain_pinecone import PineconeVectorStore
import pinecone

pinecone.init(api_key="your-api-key", environment="us-west1-gcp")
vector_store = PineconeVectorStore(index_name="schema-rag")
```

---

### Option 3: Qdrant (Self-hosted or Cloud)

#### Pros:
- âœ… High performance (Rust-based)
- âœ… Built-in filtering and payload storage
- âœ… REST + gRPC APIs
- âœ… Open source option

#### Cons:
- âŒ Separate service to manage
- âŒ Learning curve (not SQL)

#### Setup:
```bash
# Docker deployment
docker run -p 6333:6333 qdrant/qdrant

# Python
from langchain_qdrant import QdrantVectorStore
vector_store = QdrantVectorStore.from_documents(
    docs, embeddings, url="http://localhost:6333"
)
```

---

### Option 4: Weaviate (AI-Native)

#### Pros:
- âœ… Built-in vectorization (no separate embeddings)
- âœ… GraphQL API
- âœ… Hybrid search (vector + keyword)
- âœ… Multi-tenancy support

#### Cons:
- âŒ Complex setup
- âŒ Resource-intensive

#### Setup:
```bash
docker-compose up -d  # From Weaviate compose file

# Python
from langchain_weaviate import WeaviateVectorStore
vector_store = WeaviateVectorStore(client=weaviate_client)
```

---

### Option 5: ChromaDB (Lightweight)

#### Pros:
- âœ… Easiest setup (pip install)
- âœ… Embedded or client-server mode
- âœ… Good for prototyping
- âœ… Open source

#### Cons:
- âŒ Not production-ready for scale
- âŒ Limited concurrent access

#### Setup:
```python
from langchain_chroma import Chroma
vector_store = Chroma.from_documents(
    docs, embeddings, persist_directory="./chroma_db"
)
```

---

## ğŸ“Š Comparison Table

| Feature | pgvector | Pinecone | Qdrant | Weaviate | ChromaDB | FAISS |
|---------|----------|----------|--------|----------|----------|-------|
| **Persistence** | âœ… PostgreSQL | âœ… Cloud | âœ… Disk/Cloud | âœ… Disk/Cloud | âœ… Disk | âŒ Memory |
| **Cost** | Free | $70+/mo | Free (self) | Free (self) | Free | Free |
| **Speed** | â­â­â­ | â­â­â­â­â­ | â­â­â­â­ | â­â­â­â­ | â­â­â­ | â­â­â­â­â­ |
| **Scalability** | 1M+ vectors | 100M+ | 10M+ | 10M+ | 100K | 1M+ |
| **Setup** | Easy | Easiest | Medium | Hard | Easiest | Easiest |
| **Concurrent** | âœ… | âœ… | âœ… | âœ… | âš ï¸ | âŒ |
| **Production** | âœ… | âœ… | âœ… | âœ… | âš ï¸ | âŒ |

---

## ğŸš€ Using pgvector in This System

### Installation:

```bash
# 1. Install PostgreSQL extension
# Ubuntu/Debian:
sudo apt-get install postgresql-15-pgvector

# macOS (Homebrew):
brew install pgvector

# Windows: Download from https://github.com/pgvector/pgvector/releases
```

```sql
-- 2. Enable in your database
CREATE EXTENSION vector;
```

```bash
# 3. Install Python dependencies
pip install psycopg2-binary sentence-transformers
```

### Configuration:

```python
# In config.py, add:
from tools.schema_rag_pgvector import initialize_rag

# Initialize RAG with same database connection
initialize_rag("postgresql://user1:password@localhost:5432/entegris_db")
```

### Usage:

```python
from tools.schema_rag_pgvector import get_relevant_schema, add_schema_document

# Retrieve schema for a query
schema = get_relevant_schema("Show me revenue from Germany")
# Returns: Top 3 most relevant schema docs

# Add new schema documentation dynamically
add_schema_document(
    content="""Table: customers
    Columns: customer_id, first_name, last_name, email, country
    Used for customer analysis and segmentation""",
    table_name="customers",
    doc_type="full_schema",
    priority=1
)
```

---

## ğŸ¯ Best Practices

### 1. **Comprehensive Schema Docs**
- Include all column names, types, constraints
- Add valid enum values (countries, categories)
- Document business logic (revenue = units Ã— price)
- Provide query examples

### 2. **Granular Documents**
- One document per table (full schema)
- Separate documents for each column with enums
- Business logic in dedicated docs
- Enables precise retrieval

### 3. **Regular Updates**
- Auto-refresh when schema changes
- Add new tables immediately
- Update business rules as they evolve

### 4. **Monitoring**
- Log cosine distances (detect poor matches)
- Track which docs are retrieved most
- Identify gaps in documentation

### 5. **Hybrid Approach**
- Combine RAG with validation (our system does this!)
- Use RAG for schema â†’ Validator for correctness
- Retry agent for error recovery

---

## ğŸ” Example RAG Flow in Action

### User Query:
```
"What are the top 3 products by revenue in Germany?"
```

### Step 1: Embedding
```python
query_embedding = embeddings.embed_query(query)
# [0.45, -0.23, 0.67, ..., 0.12]  (384 dimensions)
```

### Step 2: Retrieval
```sql
SELECT content, (embedding <=> '[0.45,-0.23,...]'::vector) as distance
FROM schema_embeddings
ORDER BY distance ASC
LIMIT 3;
```

### Results:
```
1. "Table: sales_data, Column: total_revenue..." (distance: 0.08)
2. "Country values: USA, Germany, France..." (distance: 0.12)
3. "Top products query: SELECT product_name, SUM..." (distance: 0.15)
```

### Step 3: Augmented Prompt
```
Context:
- sales_data table has total_revenue column for revenue calculations
- country column contains 'Germany' as valid value
- Use SUM(total_revenue) and GROUP BY product_name for aggregation

User Question: What are the top 3 products by revenue in Germany?

Generate accurate SQL query.
```

### Step 4: LLM Generation
```sql
SELECT product_name, SUM(total_revenue) as revenue
FROM sales_data
WHERE country = 'Germany'
GROUP BY product_name
ORDER BY revenue DESC
LIMIT 3;
```

âœ… **Perfect query with accurate table/column names!**

---

## ğŸ“ˆ Performance Tuning

### For pgvector:

```sql
-- Increase index lists for better recall (at cost of speed)
CREATE INDEX ON schema_embeddings 
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);  -- Higher = better recall, slower queries

-- Analyze table for query optimization
ANALYZE schema_embeddings;

-- Monitor query performance
EXPLAIN ANALYZE
SELECT * FROM schema_embeddings
ORDER BY embedding <=> '[...]'::vector
LIMIT 3;
```

### For Python:

```python
# Cache embeddings model (done automatically)
embeddings = HuggingFaceEmbeddings(
    model_name="sentence-transformers/all-MiniLM-L6-v2",
    cache_folder="./model_cache"  # Reuse across restarts
)

# Batch processing for bulk schema updates
embeddings.embed_documents([doc1, doc2, doc3])  # Faster than 3 separate calls
```

---

## ğŸ“ Further Learning

- **LangChain RAG Tutorial**: https://python.langchain.com/docs/use_cases/question_answering/
- **pgvector Documentation**: https://github.com/pgvector/pgvector
- **Sentence Transformers**: https://www.sbert.net/
- **Vector Database Comparison**: https://superlinked.com/vector-db-comparison/

---

## ğŸ Summary

**RAG in this system**:
1. **Embeddings**: Convert schema docs to 384-dim vectors (HuggingFace)
2. **Storage**: Store vectors in PostgreSQL with pgvector
3. **Retrieval**: Find top-k similar docs using cosine distance
4. **Augmentation**: LLM receives query + retrieved schema
5. **Generation**: LLM produces accurate SQL with correct names

**Why pgvector?**
- Same database as your data
- Persistent, scalable, transactional
- SQL interface (no new tools to learn)
- Production-ready and free

**Result**: 95%+ accuracy in table/column name resolution! ğŸ¯
